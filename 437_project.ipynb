{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["***GOOGLE API AUTHORIZATION***<br>\n","via OAuth 2.0"],"metadata":{"id":"e6S612GczpbD"}},{"cell_type":"code","source":["# Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"pCtu61vf8ARp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install correct versions so that OAuth Flow has run_console() method\n","!pip install 'google-api-python-client==1.7.2'\n","!pip install 'google-auth==1.8.0'\n","!pip install 'google-auth-httplib2==0.0.3'\n","!pip install 'google-auth-oauthlib==0.4.1'\n","!pip install nltk==3.5"],"metadata":{"id":"KPLJhRgnN7UM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Log into gmail to scrape it for email data\n","from google_auth_oauthlib.flow import InstalledAppFlow\n","from googleapiclient.discovery import build\n","\n","# Get the credentials json file and establish scope\n","credentials = '/content/drive/MyDrive/client_secret.apps.googleusercontent.com.json'\n","scope = ['https://www.googleapis.com/auth/gmail.readonly']\n","\n","# Use flow and scope to authorize gmail\n","flow = InstalledAppFlow.from_client_secrets_file(credentials, scope)\n","creds = flow.run_console()"],"metadata":{"id":"aulfFBtA9Y0w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***CLEANING AND FORMATTING EMAILS***"],"metadata":{"id":"Ptp1K9PrFSTv"}},{"cell_type":"code","source":["import random\n","service = build('gmail', 'v1', credentials=creds)\n","\n","# Call the Gmail API to find non-SPAM and SPAM emails\n","results = service.users().messages().list(userId='me', maxResults=100).execute()\n","messages = results.get('messages', [])\n","\n","results = service.users().messages().list(userId='me', labelIds=['SPAM'], maxResults=50).execute()\n","spam_messages = results.get('messages', [])\n","\n","#combine SPAM and non-SPAM\n","messages = messages + spam_messages\n","random.shuffle(messages)"],"metadata":{"id":"6Qv7WoxqBjL1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#breaking down emails\n","import numpy as np\n","import pandas as pd\n","import nltk\n","import string\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","#download necessary nltk dependencies\n","nltk.download(\"stopwords\")\n","nltk.download(\"punkt\")\n","stop_words = set(stopwords.words(\"english\"))\n","\n","#initialize all variables\n","x = []\n","y = []\n","word_token={}\n","itr = 0\n","\n","#iterate over each message\n","for message in messages:\n","\n","  #extract the contents of the message\n","  msg = service.users().messages().get(userId='me', id=message['id']).execute()\n","  text = msg['snippet']\n","\n","  #normalize the text (alphabetic and lowercase) then tokenize\n","  text = \"\".join([i.lower() for i in text if (i.isalpha() or i == \" \")])\n","  words = word_tokenize(text)\n","\n","  #loop over each word in the tokenized message\n","  w = []\n","  for word in words:\n","    #accept words only if they have a length of 2 or greater and not stopword and append\n","    if word not in stop_words and len(word) > 2:\n","      #check if the word is already assigned an ID\n","      if word not in word_token.keys():\n","        #assign an ID to the word\n","        word_token[word] = itr\n","        itr+=1\n","      w.append(word_token[word])\n","  x.append(w)\n","\n","  #append a value indicating if a message is SPAM or not\n","  if 'SPAM' in msg.get('labelIds', []):\n","    y.append(1)\n","  else:\n","    y.append(0)\n","\n","#creating bag-of-words:\n","to_numpy = []\n","for tokens in x:\n","  arr=np.zeros(itr)\n","  for token in tokens:\n","    arr[token] +=1\n","  to_numpy.append(arr)\n","\n","#stack rows to create a numpy matrix\n","bag_of_words = np.row_stack(to_numpy)\n","\n","\n"],"metadata":{"id":"1s4O2z0t-R1h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***MOVE FORMATTED DATA TO EXCEL FILE***"],"metadata":{"id":"AqavoEO0s69E"}},{"cell_type":"code","source":["new_y = np.vstack(np.asarray(y))\n","all_data = np.append(bag_of_words, new_y, axis=1)\n","np.save('/content/drive/MyDrive/CptS_437/email_data.npy', all_data)"],"metadata":{"id":"tg2_Ib8_qTLE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***CLASSIFIER WITH RUNTIME VARIABLES***"],"metadata":{"id":"XzcBSP_RFXRU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZfNC8WztUU2"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","\n","# initialize variables for training and testing\n","n_evaluations = 100\n","testsize = .9\n","train_acc=[]\n","test_acc=[]\n","# Splitting the dataset into training and testing sets\n","for i in range(9):\n","  train_accuracies = []\n","  test_accuracies = []\n","  for i in range(n_evaluations):\n","    X_train, X_test, y_train, y_test = train_test_split(bag_of_words , y, test_size=testsize, random_state = random.randint(0,1000))\n","\n","    # Train Naive Bayes classifier\n","    clf = MultinomialNB()\n","    clf.fit(X_train, y_train)\n","\n","    # Predict on test data\n","    y_pred = clf.predict(X_test)\n","\n","    train_accuracy = clf.score(X_train, y_train)\n","    test_accuracy = accuracy_score(y_test, y_pred)\n","\n","    # Store accuracies for later analysis or visualization\n","    train_accuracies.append(train_accuracy)\n","    test_accuracies.append(test_accuracy)\n","  train_acc.append(sum(train_accuracies) / 100)\n","  test_acc.append(sum(test_accuracies) / 100)\n","  testsize -=.1\n","\n","# Plotting the training and testing accuracies over different evaluation runs\n","evaluation_runs = [10,20,30,40,50,60,70,80,90]\n","plt.plot(evaluation_runs, train_acc, label='Training Accuracy', marker='o')\n","plt.plot(evaluation_runs, test_acc, label='Testing Accuracy', marker='o')\n","\n","plt.xlabel('% of Training data (remainder is testing)')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Testing Accuracies')\n","plt.ylim(.5, 1)\n","\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","source":["***RUN CLASSIFIER WITH SAVED .npy FILE***"],"metadata":{"id":"QBYaipR2vfh8"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","\n","# Get .npy file from Drive\n","drive.mount('/content/drive', force_remount=True)\n","all_data = np.load('/content/drive/MyDrive/CptS_437/email_data.npy')\n","x = all_data[:,:-1]\n","new_y = all_data[:,-1:].reshape(1, -1)[0]\n","\n","# initialize variables for training and testing\n","n_evaluations = 100\n","testsize = .9\n","train_acc=[]\n","test_acc=[]\n","# Splitting the dataset into training and testing sets\n","for i in range(9):\n","  train_accuracies = []\n","  test_accuracies = []\n","  for i in range(n_evaluations):\n","    X_train, X_test, y_train, y_test = train_test_split(x , new_y, test_size=testsize, random_state = random.randint(0,1000))\n","\n","    # Train Naive Bayes classifier\n","    clf = MultinomialNB()\n","    clf.fit(X_train, y_train)\n","\n","    # Predict on test data\n","    y_pred = clf.predict(X_test)\n","\n","    train_accuracy = clf.score(X_train, y_train)\n","    test_accuracy = accuracy_score(y_test, y_pred)\n","\n","    # Store accuracies for later analysis or visualization\n","    train_accuracies.append(train_accuracy)\n","    test_accuracies.append(test_accuracy)\n","  train_acc.append(sum(train_accuracies) / 100)\n","  test_acc.append(sum(test_accuracies) / 100)\n","  testsize -=.1\n","\n","# Plotting the training and testing accuracies over different evaluation runs\n","evaluation_runs = [10,20,30,40,50,60,70,80,90]\n","plt.plot(evaluation_runs, train_acc, label='Training Accuracy', marker='o')\n","plt.plot(evaluation_runs, test_acc, label='Testing Accuracy', marker='o')\n","\n","plt.xlabel('% of Training data (remainder is testing)')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Testing Accuracies')\n","plt.ylim(.5, 1)\n","\n","plt.legend()\n","plt.show()"],"metadata":{"id":"gMjIh6gnvjmc"},"execution_count":null,"outputs":[]}]}